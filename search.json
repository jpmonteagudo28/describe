[{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU Affero General Public License","title":"GNU Affero General Public License","text":"Version 3, 19 November 2007 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU Affero General Public License","text":"GNU Affero General Public License free, copyleft license software kinds works, specifically designed ensure cooperation community case network server software. licenses software practical works designed take away freedom share change works. contrast, General Public Licenses intended guarantee freedom share change versions program–make sure remains free software users. speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. Developers use General Public Licenses protect rights two steps: (1) assert copyright software, (2) offer License gives legal permission copy, distribute /modify software. secondary benefit defending users’ freedom improvements made alternate versions program, receive widespread use, become available developers incorporate. Many developers free software heartened encouraged resulting cooperation. However, case software used network servers, result may fail come . GNU General Public License permits making modified version letting public access server without ever releasing source code public. GNU Affero General Public License designed specifically ensure , cases, modified source code becomes available community. requires operator network server provide source code modified version running users server. Therefore, public use modified version, publicly accessible server, gives public access source code modified version. older license, called Affero General Public License published Affero, designed accomplish similar goals. different license, version Affero GPL, Affero released new version Affero GPL permits relicensing license. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions.","title":"GNU Affero General Public License","text":"“License” refers version 3 GNU Affero General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code.","title":"GNU Affero General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions.","title":"GNU Affero General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law.","title":"GNU Affero General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies.","title":"GNU Affero General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions.","title":"GNU Affero General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: work must carry prominent notices stating modified , giving relevant date. work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms.","title":"GNU Affero General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms.","title":"GNU Affero General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: Disclaiming warranty limiting liability differently terms sections 15 16 License; Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; Limiting use publicity purposes names licensors authors material; Declining grant rights trademark law use trade names, trademarks, service marks; Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination.","title":"GNU Affero General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies.","title":"GNU Affero General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients.","title":"GNU Affero General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents.","title":"GNU Affero General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom.","title":"GNU Affero General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_13-remote-network-interaction-use-with-the-gnu-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Remote Network Interaction; Use with the GNU General Public License.","title":"GNU Affero General Public License","text":"Notwithstanding provision License, modify Program, modified version must prominently offer users interacting remotely computer network (version supports interaction) opportunity receive Corresponding Source version providing access Corresponding Source network server charge, standard customary means facilitating copying software. Corresponding Source shall include Corresponding Source work covered version 3 GNU General Public License incorporated pursuant following paragraph. Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU General Public License single combined work, convey resulting work. terms License continue apply part covered work, work combined remain governed version 3 GNU General Public License.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License.","title":"GNU Affero General Public License","text":"Free Software Foundation may publish revised /new versions GNU Affero General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU Affero General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU Affero General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU Affero General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty.","title":"GNU Affero General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability.","title":"GNU Affero General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16.","title":"GNU Affero General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://describe.jpmonteagudo.com/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU Affero General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. software can interact users remotely computer network, also make sure provides way users get source. example, program web application, interface display “Source” link leads users archive code. many ways offer source, different solutions better different programs; see section 13 specific requirements. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU AGPL, see https://www.gnu.org/licenses/.","code":"<one line to give the program's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>      This program is free software: you can redistribute it and/or modify     it under the terms of the GNU Affero General Public License as     published by the Free Software Foundation, either version 3 of the     License, or (at your option) any later version.      This program is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the     GNU Affero General Public License for more details.      You should have received a copy of the GNU Affero General Public License     along with this program.  If not, see <https://www.gnu.org/licenses/>."},{"path":"https://describe.jpmonteagudo.com/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"JP Monteagudo. Author, maintainer, copyright holder.","code":""},{"path":"https://describe.jpmonteagudo.com/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Monteagudo J (2024). describe: Compute varied descriptive statistics,create visualizations handle missing data. R package version 0.0.0.9000, https://github.com/jpmonteagudo28/describe.","code":"@Manual{,   title = {describe: Compute varied descriptive statistics,create visualizations and handle missing data},   author = {JP Monteagudo},   year = {2024},   note = {R package version 0.0.0.9000},   url = {https://github.com/jpmonteagudo28/describe}, }"},{"path":"https://describe.jpmonteagudo.com/index.html","id":"describe-","dir":"","previous_headings":"","what":"Compute varied descriptive statistics,create visualizations and handle missing data","title":"Compute varied descriptive statistics,create visualizations and handle missing data","text":"goal describe make easy compute descriptive statistics non-normal distributions without creating custom functions spending hours researching stack overflow. package also provides flexible intuitive univariate multiple data imputation visualizations exploratory data analysis.","code":""},{"path":"https://describe.jpmonteagudo.com/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Compute varied descriptive statistics,create visualizations and handle missing data","text":"can install development version describe like : can also install CRAN like :","code":"devtools::install_github(\"jpmonteagudo28/describe\") install.packages(\"describe\")"},{"path":"https://describe.jpmonteagudo.com/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Compute varied descriptive statistics,create visualizations and handle missing data","text":"basic example shows solve common problem: special using README.Rmd instead just README.md? can include R chunks like : ’ll still need render README.Rmd regularly, keep README.md --date. devtools::build_readme() handy . can also embed plots, example:  case, don’t forget commit push resulting figure files, display GitHub CRAN.","code":"library(describe)  # Generate random data with NAs data <- gen.mcar(50,rho = .467,sigma = c(1,1.3),n_vars = 2, na_prob = .10)  # Impute missing values using predictive mean matching imputed_data <- pmean.match(data, robust = TRUE, verbose = TRUE) #> Initial missing values: 8 (8.00%) #> Remaining missing values: 0 (0.00%)  head(imputed_data,10) #>            V1         V2 #> 1   1.7945695 -0.8437137 #> 2   0.8450450 -0.4223777 #> 3   1.5095428  2.0415957 #> 4   0.0367590  0.3120576 #> 5   0.5888666  0.6589248 #> 6   0.4108906 -0.2331285 #> 7  -2.3065881 -3.2270210 #> 8  -0.5356565  0.6062233 #> 9   0.9194851 -0.4223777 #> 10  0.6637492  1.4249718  summary(imputed_data) #>        V1                 V2          #>  Min.   :-2.30659   Min.   :-3.2270   #>  1st Qu.:-0.94678   1st Qu.:-0.4224   #>  Median : 0.05330   Median : 0.2962   #>  Mean   :-0.05093   Mean   : 0.1442   #>  3rd Qu.: 0.66375   3rd Qu.: 0.8352   #>  Max.   : 2.43697   Max.   : 2.5081 # Some examples of bootstrapped correlation coefficients and geometric median"},{"path":"https://describe.jpmonteagudo.com/reference/check.mar.html","id":null,"dir":"Reference","previous_headings":"","what":"MAR check using logistic regression — check.mar","title":"MAR check using logistic regression — check.mar","text":"can informally test data missing random (MAR) creating binary variable represents missing data (1) non-missing data (0). perform logistic regression using binary variable target obtain p-values. Pairwise comparisons performed unique pair p-values obtained applying Dunn-Šidák correction. test formal test used check MAR. Additionally, tests missingness may practical substitute knowledge field much better joint tests dealing missingness.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.mar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MAR check using logistic regression — check.mar","text":"","code":"check.mar(data, digits = 3)"},{"path":"https://describe.jpmonteagudo.com/reference/check.mar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MAR check using logistic regression — check.mar","text":"data data frame matrix least two columns digits significant figures used decimals","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.mar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MAR check using logistic regression — check.mar","text":"square matrix p-values across pairwise comparisons","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.mar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MAR check using logistic regression — check.mar","text":"","code":"set.seed(123) data <- data.frame(x1 = stats::rnorm(100),x2 = stats::rnorm(100),y = stats::rnorm(100)) data$x1[sample(1:100, 20)] <- NA data$x2[sample(1:100, 15)] <- NA data$y[sample(1:100, 10)] <- NA  check.mar(data, digits = 2) #> Adjusted p-values of pair-wise comparisons  #>         x1 x2    y is_na #> x1      NA  1 0.69     1 #> x2    1.00 NA 1.00     1 #> y     0.69  1   NA     1 #> is_na 1.00  1 1.00    NA"},{"path":"https://describe.jpmonteagudo.com/reference/check.mcar.html","id":null,"dir":"Reference","previous_headings":"","what":"Little's test for missing completely at random (MCAR) — check.mcar","title":"Little's test for missing completely at random (MCAR) — check.mcar","text":"Little's test MCAR data modeled multidimensional, multivariate normal mean 'mu' covariance matrix 'sigma'. test statistic sum squared standardized differences sub-sample means expected population means weighted variance-covariance matrix number observations. null hypothesis, test statistic follows chi-square distribution \\(\\sum k_j - k\\) degrees freedom, \\(k_j\\) number complete variables missing data pattern \\(j\\), \\(k\\) total number variables. statistically significant result provides evidence MCAR. normality assumption  satisfied, test work quantitative random variables categorical ones. Additionally, test specify variable(s) MCAR, fails identify collinearity among variables. Third, test can neither prove MCAR assumption rule hypothesis MNAR.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.mcar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Little's test for missing completely at random (MCAR) — check.mcar","text":"","code":"check.mcar(data, digits = 3)"},{"path":"https://describe.jpmonteagudo.com/reference/check.mcar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Little's test for missing completely at random (MCAR) — check.mcar","text":"data data frame matrix least two columns digits significant figures used decimals","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.mcar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Little's test for missing completely at random (MCAR) — check.mcar","text":"numeric matrix statistic Chi-squared statistic Little's test df Degrees freedom used compute chi-square statistic p_value P-value chi-square statistic pattern Unique missing data patterns found","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.mcar.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Little's test for missing completely at random (MCAR) — check.mcar","text":"Little, R. J. . (1988). test Missing Completely Random multivariate data missing values. Journal American Statistical Association, 83, 1198-1202. https://doi.org/10.2307/2290157 code adapted Eric Stemmler: https://web.archive.org/web/20201120030409/https://stats-bayes.com/post/2020/08/14/r-function--little-s-test--data-missing-completely--random/ naniar's mcar_test.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.mcar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Little's test for missing completely at random (MCAR) — check.mcar","text":"","code":"set.seed(123) data <- data.frame(x1 = stats::rnorm(100),x2 = stats::rnorm(100),y = stats::rnorm(100)) data$x1[sample(1:100, 20)] <- NA data$x2[sample(1:100, 15)] <- NA data$y[sample(1:100, 10)] <- NA check.mcar(data,digits = 3) #> Little's test of MCAR #>   statistic df p.value missing.patterns #> 1     5.484  9    0.79                7"},{"path":"https://describe.jpmonteagudo.com/reference/check.missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Check percent of missing values in data frame or matrix pre and post-processing — check.missing","title":"Check percent of missing values in data frame or matrix pre and post-processing — check.missing","text":"check.missing takes data frame compares percentage missing values pre post-processing within one imputation function. missing values completely replaced imputed values, remaining percent missing 0, otherwise user see warning indicating imputation performed regressors used model contained missing values.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check percent of missing values in data frame or matrix pre and post-processing — check.missing","text":"","code":"check.missing(data, post_data = NULL, verbose = FALSE)"},{"path":"https://describe.jpmonteagudo.com/reference/check.missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check percent of missing values in data frame or matrix pre and post-processing — check.missing","text":"data data frame matrix prior processing post_data data frame matrix processing verbose indicate verbose warning error messages","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.missing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check percent of missing values in data frame or matrix pre and post-processing — check.missing","text":"character vector specifying percent missing values processing","code":""},{"path":"https://describe.jpmonteagudo.com/reference/check.missing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check percent of missing values in data frame or matrix pre and post-processing — check.missing","text":"","code":"set.seed(123) data <- data.frame(x1 = stats::rnorm(100),x2 = stats::rnorm(100),y = stats::rnorm(100)) data$x1[sample(1:100, 20)] <- NA data$x2[sample(1:100, 15)] <- NA data$y[sample(1:100, 10)] <- NA  check.missing(data, data, verbose = TRUE) #> Initial missing values: 45 (15.00%) #> Remaining missing values: 45 (15.00%) #> Warning: Initial missing: 15.00%. Remaining missing: 15.00%. Imputation not performed or missing values in the regressors."},{"path":"https://describe.jpmonteagudo.com/reference/cmean.impute.html","id":null,"dir":"Reference","previous_headings":"","what":"Imputation of missing values through conditional mean imputation (CMI). — cmean.impute","title":"Imputation of missing values through conditional mean imputation (CMI). — cmean.impute","text":"method replaces missing values expected value missing variable, given variables dataset. Predictions conditional mean performed using specific regression models. CMI univariate imputation method leverages relationship variables data make informed predictions missing values. Although method reduces bias aims maintain relationship among variables, yield residuals less variation original data. CMI fail regressor also contains missing values, thus making imputation target's missing values impossible. user want understand fill much missing data possible imputing method. regressors contain missing values, better use multiple imputation techniques.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/cmean.impute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Imputation of missing values through conditional mean imputation (CMI). — cmean.impute","text":"","code":"cmean.impute(   data,   family = \"AUTO\",   robust = FALSE,   char_to_factor = FALSE,   verbose = FALSE )"},{"path":"https://describe.jpmonteagudo.com/reference/cmean.impute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Imputation of missing values through conditional mean imputation (CMI). — cmean.impute","text":"data numeric matrix data frame least 2 columns. family distribution family observations. family arguments defaults 'AUTO'; automatically select distribution family (gaussian, binomial, multinomial) based type variable (numeric factor). distribution family dictates regression model used (lm,glm, multinom). However, user can change family argument match response variable distribution function adapt input using generalized linear model beta regression. robust logical indicated whether use robust estimation methods ignore . set 'TRUE', function make use robust linear generalized linear models make prediction. char_to_factor transform character variable unordered factor variable verbose verbose error handling","code":""},{"path":"https://describe.jpmonteagudo.com/reference/cmean.impute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Imputation of missing values through conditional mean imputation (CMI). — cmean.impute","text":"matrix data frame containing imputed dataset.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/cmean.impute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imputation of missing values through conditional mean imputation (CMI). — cmean.impute","text":"","code":"set.seed(123) data <- data.frame(x1 = c(stats::rnorm(87),rep(NA,13)), x2 = stats::rnorm(100),y = stats::rnorm(100)) cmean.impute(data) #>                x1          x2           y #> 1   -0.5604756466  0.43518149  0.08473729 #> 2   -0.2301774895 -0.32593159  0.75405379 #> 3    1.5587083141  1.14880762 -0.49929202 #> 4    0.0705083914  0.99350386  0.21444531 #> 5    0.1292877352  0.54839696 -0.32468591 #> 6    1.7150649869  0.23873174  0.09458353 #> 7    0.4609162060 -0.62790608 -0.89536336 #> 8   -1.2650612346  1.36065245 -1.31080153 #> 9   -0.6868528519 -0.60025959  1.99721338 #> 10  -0.4456619701  2.18733299  0.60070882 #> 11   1.2240817974  1.53261063 -1.25127136 #> 12   0.3598138271 -0.23570036 -0.61116592 #> 13   0.4007714506 -1.02642090 -1.18548008 #> 14   0.1106827159 -0.71040656  2.19881035 #> 15  -0.5558411348  0.25688371  1.31241298 #> 16   1.7869131368 -0.24669188 -0.26514506 #> 17   0.4978504782 -0.34754260  0.54319406 #> 18  -1.9666171566 -0.95161857 -0.41433995 #> 19   0.7013559016 -0.04502772 -0.47624689 #> 20  -0.4727914077 -0.78490447 -0.78860284 #> 21  -1.0678237060 -1.66794194 -0.59461727 #> 22  -0.2179749147 -0.38022652  1.65090747 #> 23  -1.0260044483  0.91899661 -0.05402813 #> 24  -0.7288912293 -0.57534696  0.11924524 #> 25  -0.6250392678  0.60796432  0.24368743 #> 26  -1.6866933107 -1.61788271  1.23247588 #> 27   0.8377870445 -0.05556197 -0.51606383 #> 28   0.1533731178  0.51940720 -0.99250715 #> 29  -1.1381369370  0.30115336  1.67569693 #> 30   1.2538149211  0.10567619 -0.44116322 #> 31   0.4264642215 -0.64070601 -0.72306597 #> 32  -0.2950714830 -0.84970435 -1.23627312 #> 33   0.8951256610 -1.02412879 -1.28471572 #> 34   0.8781334875  0.11764660 -0.57397348 #> 35   0.8215810816 -0.94747461  0.61798582 #> 36   0.6886402541 -0.49055744  1.10984814 #> 37   0.5539176535 -0.25609219  0.70758835 #> 38  -0.0619117106  1.84386201 -0.36365730 #> 39  -0.3059626637 -0.65194990  0.05974994 #> 40  -0.3804710010  0.23538657 -0.70459646 #> 41  -0.6947069789  0.07796085 -0.71721816 #> 42  -0.2079172780 -0.96185663  0.88465050 #> 43  -1.2653963516 -0.07130809 -1.01559258 #> 44   2.1689559653  1.44455086  1.95529397 #> 45   1.2079619983  0.45150405 -0.09031959 #> 46  -1.1231085832  0.04123292  0.21453883 #> 47  -0.4028848353 -0.42249683 -0.73852770 #> 48  -0.4666553536 -2.05324722 -0.57438869 #> 49   0.7799651183  1.13133721 -1.31701613 #> 50  -0.0833690665 -1.46064007 -0.18292539 #> 51   0.2533185140  0.73994751  0.41898240 #> 52  -0.0285467553  1.90910357  0.32430434 #> 53  -0.0428704573 -1.44389316 -0.78153649 #> 54   1.3686022840  0.70178434 -0.78862197 #> 55  -0.2257709857 -0.26219749 -0.50219872 #> 56   1.5164706044 -1.57214416  1.49606067 #> 57  -1.5487528042 -1.51466765 -1.13730362 #> 58   0.5846137496 -1.60153617 -0.17905159 #> 59   0.1238542438 -0.53090652  1.90236182 #> 60   0.2159415687 -1.46175558 -0.10097489 #> 61   0.3796394828  0.68791677 -1.35984070 #> 62  -0.5023234531  2.10010894 -0.66476944 #> 63  -0.3332073837 -1.28703048  0.48545998 #> 64  -1.0185753831  0.78773885 -0.37560287 #> 65  -1.0717912265  0.76904224 -0.56187636 #> 66   0.3035286414  0.33220258 -0.34391723 #> 67   0.4482097786 -1.00837661  0.09049665 #> 68   0.0530042267 -0.11945261  1.59850877 #> 69   0.9222674679 -0.28039534 -0.08856511 #> 70   2.0500846856  0.56298953  1.08079950 #> 71  -0.4910311661 -0.37243876  0.63075412 #> 72  -2.3091688756  0.97697339 -0.11363990 #> 73   1.0057385245 -0.37458086 -1.53290200 #> 74  -0.7092007626  1.05271147 -0.52111732 #> 75  -0.6880086165 -1.04917701 -0.48987045 #> 76   1.0255713697 -1.26015524  0.04715443 #> 77  -0.2847730071  3.24103993  1.30019868 #> 78  -1.2207177123 -0.41685759  2.29307897 #> 79   0.1813034797  0.29822759  1.54758106 #> 80  -0.1388913624  0.63656967 -0.13315096 #> 81   0.0057641859 -0.48378063 -1.75652740 #> 82   0.3852804011  0.51686204 -0.38877986 #> 83  -0.3706600318  0.36896453  0.08920722 #> 84   0.6443765485 -0.21538051  0.84501300 #> 85  -0.2204865618  0.06529303  0.96252797 #> 86   0.3317819639 -0.03406725  0.68430943 #> 87   1.0968390131  2.12845190 -1.39527435 #> 88  -0.0276652061 -0.74133610  0.84964305 #> 89  -0.0269552971 -1.09599627 -0.44655722 #> 90   0.0393325276  0.03778840  0.17480270 #> 91   0.0601357370  0.31048075  0.07455118 #> 92   0.0619668342  0.43652348  0.42816676 #> 93   0.0079540668 -0.45836533  0.02467498 #> 94  -0.0009334397 -1.06332613 -1.66747510 #> 95   0.1131150673  1.26318518  0.73649596 #> 96   0.0084366776 -0.34965039  0.38602657 #> 97  -0.0145423967 -0.86551286 -0.26565163 #> 98   0.0214882232 -0.23627957  0.11814451 #> 99   0.0238822124 -0.19717589  0.13403865 #> 100  0.1125524006  1.10992029  0.22101947"},{"path":"https://describe.jpmonteagudo.com/reference/coldeck.impute.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute values in X by randomly selecting data points from recorded observations in Y from an external, pre-existing data source. — coldeck.impute","title":"Impute values in X by randomly selecting data points from recorded observations in Y from an external, pre-existing data source. — coldeck.impute","text":"Cold deck imputation (CDI) univariate imputation technique , respondent recipient missing value, use external, pre-existing source find donor similar values across subset categorical numerical predictors use fill recipient's missing observation. reason, cold deck imputation used stratification across categorical variables. current implementation CDI allows user choose one four selection methods: deterministic, random sampling possible donors, k-nearest neighbors random sampling using weights probabilities. function iteratively impute missing values across variables missing observations using selection method specified function arguments.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/coldeck.impute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute values in X by randomly selecting data points from recorded observations in Y from an external, pre-existing data source. — coldeck.impute","text":"","code":"coldeck.impute(   data,   ext_data = NULL,   method = \"deterministic\",   k = NULL,   seed = NULL,   na.rm = TRUE )"},{"path":"https://describe.jpmonteagudo.com/reference/coldeck.impute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute values in X by randomly selecting data points from recorded observations in Y from an external, pre-existing data source. — coldeck.impute","text":"data matrix data frame containing missing values least one predictor ext_data external data source complete cases used donor values method selection method imputing missing values based donor similarity. Can one : \"deterministic\" Select donor value multiple repetitions CDI. \"rand_from_all\" Select different donor value repetition CDI. \"rand_nearest_k\" Select one random donor value subset k nearest neighbors repetition CDI. \"weighted_rand\" Select one random donor probability-weighted choice repetition CDI. k number nearest neighbors select using rand_nearest_k method. seed numeric seed reproducible results every method except deterministic selection na.rm indicates removal NA values every row matrix data frame","code":""},{"path":"https://describe.jpmonteagudo.com/reference/coldeck.impute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute values in X by randomly selecting data points from recorded observations in Y from an external, pre-existing data source. — coldeck.impute","text":"matrix data frame imputed values","code":""},{"path":"https://describe.jpmonteagudo.com/reference/coldeck.impute.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Impute values in X by randomly selecting data points from recorded observations in Y from an external, pre-existing data source. — coldeck.impute","text":"CDI valuable method reliable external source data available can ensure standardized imputations, particularly large-scale studies historical consistency important. However, requires careful consideration avoid introducing bias due mismatches current dataset external source.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/coldeck.impute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute values in X by randomly selecting data points from recorded observations in Y from an external, pre-existing data source. — coldeck.impute","text":"","code":"data <- gen.mcar(100,rho = c(.56,.23,.18),sigma = c(1,2,.5),n_vars = 3,na_prob = .18) ext_data <- gen.mcar(100,rho = c(.45,.26,.21),sigma = c(1.67,2.23,.56),n_vars = 3,na_prob = 0) coldeck.impute(data,ext_data) #>               V1          V2           V3 #> 1    1.640846166  0.03642265 -0.125325398 #> 2   -0.219050379 -0.96719453 -0.562132515 #> 3    0.168065384  0.76172181 -0.154975693 #> 4    1.168383873  0.23644489 -0.025481243 #> 5    1.054181023 -2.39450533  0.736386047 #> 6    1.145263110  2.74788522  0.787452440 #> 7   -0.577468001 -2.02119630 -0.621353744 #> 8    2.002482730  0.03642265 -0.211412046 #> 9    0.066700871  2.56664605  0.180845510 #> 10   0.615799237  0.80812736  0.279074683 #> 11  -1.350902686 -0.11164635  0.737649960 #> 12   0.020983586 -2.06543127  0.140277567 #> 13   1.249914571  0.81243280  0.400920094 #> 14  -0.715242187 -0.92295249  0.030388305 #> 15  -0.752688968 -2.77944978 -0.605223161 #> 16  -0.938538704 -2.10293184  0.371075071 #> 17  -1.052513279 -1.22660490 -0.811816426 #> 18  -0.437159533  0.62171463 -0.762420438 #> 19   0.331179173 -2.36401054 -0.059120306 #> 20  -2.014210498  1.05599169 -0.677525563 #> 21   0.211980433  1.49077237 -0.957833818 #> 22   1.236675046  0.49227724  0.198469025 #> 23   0.615799237  2.65870225  0.202877962 #> 24   1.301175992  2.27293257  0.117561046 #> 25  -0.161465742  0.35964979  0.200271600 #> 26  -1.726730399 -0.85149973  0.250148104 #> 27   0.615799237 -0.87701395  0.026875964 #> 28   0.004495074 -1.07974790 -0.352617145 #> 29   0.703523903 -3.59171196 -0.357594956 #> 30  -0.105671334  0.03642265 -0.079029215 #> 31  -1.258648628 -0.69671108  0.019099340 #> 32   0.004495074  2.77371596 -0.294628889 #> 33   0.911391292  0.10067023 -0.001850647 #> 34   0.237430272  3.21453192 -0.599784166 #> 35   1.218108610  1.83888267  0.096350613 #> 36  -1.338774287 -1.29012369 -0.811816426 #> 37   0.660820298  2.84824598 -0.018695898 #> 38  -0.125689540 -1.77614977 -0.562132515 #> 39   0.683745522  0.87733482  0.331824132 #> 40  -0.060821955  3.90442272  0.667631682 #> 41   0.632960713  0.72735690  0.140682130 #> 42   1.335517615  4.20257845  0.403295979 #> 43   0.007290090 -2.37541934 -0.314804835 #> 44   1.017558637  0.82398215  0.405108385 #> 45  -1.188434035 -0.70400331 -0.370859081 #> 46  -0.183216236 -0.31103754 -0.763558893 #> 47   1.519217711  0.03519942 -0.122994765 #> 48   0.377387973  0.45458686  0.988925838 #> 49  -2.052222820  1.56889743  0.119637235 #> 50  -0.125689540 -0.34678307  0.474401635 #> 51  -0.161465742  0.35964979  0.184694273 #> 52   0.865779404 -2.71709878 -0.264709781 #> 53  -0.101883256  1.93341655 -0.071745113 #> 54   0.624187472 -1.35730241 -0.599784166 #> 55  -0.125689540  1.82763198 -0.562132515 #> 56   1.671054829  2.96503032  0.554514919 #> 57   0.056016733 -0.26847575  0.474401635 #> 58  -0.051981906 -1.12716402  0.394807255 #> 59  -1.753237359 -1.68969135  0.223129930 #> 60   0.099327594  0.83836300 -0.557084943 #> 61  -0.571850058  0.82314765  0.272076634 #> 62  -0.974009583 -4.49158277  1.004722974 #> 63  -0.179906231 -2.91295123 -0.341843720 #> 64   1.014943173  3.50689188  1.334308992 #> 65  -0.161465742  0.35964979 -0.576673352 #> 66  -0.427279287  0.24271455  0.503689262 #> 67   0.116637284  1.31567380  0.156830129 #> 68  -0.893207570  0.51935280  0.727813358 #> 69   0.333902942 -4.03513844 -0.752317829 #> 70   0.411429921  2.30051424  0.056710505 #> 71  -0.033036159 -0.84061777 -0.274666872 #> 72  -2.465898194 -1.37298181 -0.372246782 #> 73   2.571458146  2.39096101 -0.019134314 #> 74  -0.205299257  1.21489787 -0.401591626 #> 75   0.651193282  0.15192278  0.345154855 #> 76   0.273766491  1.16577154 -0.480638948 #> 77   0.648569822  0.50027479  0.826430528 #> 78   0.817659446 -0.89495367 -0.515773359 #> 79  -0.209793171  1.77000117  0.062347869 #> 80   0.378167772  1.65120827  0.325209383 #> 81  -0.945408831  1.79821914  0.229483261 #> 82  -1.538931792  1.06771288 -0.045972806 #> 83  -0.461038339  1.34774998  0.020349825 #> 84   2.416773354  5.98002632  0.805770981 #> 85  -0.125689540 -2.31558647 -0.562132515 #> 86  -0.463987243 -2.71177615 -0.473860205 #> 87   0.825379863  0.52782344  1.334308992 #> 88   0.510132547  0.21668528 -0.163940541 #> 89  -0.589481039  0.86975625  0.602188613 #> 90  -0.996780742  1.72086960  0.265220559 #> 91   0.144475705 -0.37860282  0.041582156 #> 92  -0.014307413  0.60203890  0.646098708 #> 93  -1.790281237 -2.38238411 -0.291297758 #> 94  -0.125689540  0.07258372 -0.149050447 #> 95   0.190230316  0.73344686 -0.018120114 #> 96   0.004495074  2.39652568 -0.512646114 #> 97  -1.055017043 -0.98059633  0.124576666 #> 98   0.476133278  1.71443846 -0.427749214 #> 99   1.378570137  2.83455811  0.072745554 #> 100  0.456236403  2.02675056  0.265958649"},{"path":"https://describe.jpmonteagudo.com/reference/gen.mar.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a data frame of any length containing any given number of NA values according to the missing at random mechanism. — gen.mar","title":"Generate a data frame of any length containing any given number of NA values according to the missing at random mechanism. — gen.mar","text":"Generate correlated, synthetic normal variables user-specified probability MAR. Specify column length, correlation coefficient, standard deviation, number columns desired probability missing values obtain data frame correlated observations missing values.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/gen.mar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a data frame of any length containing any given number of NA values according to the missing at random mechanism. — gen.mar","text":"","code":"gen.mar(len, rho, sigma, n_vars, na_prob)"},{"path":"https://describe.jpmonteagudo.com/reference/gen.mar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a data frame of any length containing any given number of NA values according to the missing at random mechanism. — gen.mar","text":"len number rows per column rho desired correlation coefficient generated variables. length rho must equal product n_vars half n_vars minus one. sigma desired standard deviation generated variable n_vars total number variables generated. least two variables must provided. na_prob desired probability missingness variable.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/gen.mar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a data frame of any length containing any given number of NA values according to the missing at random mechanism. — gen.mar","text":"data frame least 2 columns","code":""},{"path":"https://describe.jpmonteagudo.com/reference/gen.mar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a data frame of any length containing any given number of NA values according to the missing at random mechanism. — gen.mar","text":"","code":"syn_na <- gen.mar(50,c(.25,.75,.044),c(1.1,.56,1.56),3,.47)"},{"path":"https://describe.jpmonteagudo.com/reference/gen.mcar.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a data frame of any length containing any given number of NA values according to the missing completely at random mechanism. — gen.mcar","title":"Generate a data frame of any length containing any given number of NA values according to the missing completely at random mechanism. — gen.mcar","text":"Generate correlated, synthetic normal variables user-specified probability MCAR. Specify column length, correlation coefficient, standard deviation, number columns desired probability missing values obtain data frame correlated observations missing values.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/gen.mcar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a data frame of any length containing any given number of NA values according to the missing completely at random mechanism. — gen.mcar","text":"","code":"gen.mcar(len, rho, sigma, n_vars, na_prob = 0)"},{"path":"https://describe.jpmonteagudo.com/reference/gen.mcar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a data frame of any length containing any given number of NA values according to the missing completely at random mechanism. — gen.mcar","text":"len number rows per column rho desired correlation coefficient generated variables. length rho must equal product n_vars half n_vars minus one. sigma desired standard deviation generated variable n_vars total number variables generated. least two variables must provided. na_prob desired probability missingness variable.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/gen.mcar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a data frame of any length containing any given number of NA values according to the missing completely at random mechanism. — gen.mcar","text":"data frame least 2 columns","code":""},{"path":"https://describe.jpmonteagudo.com/reference/gen.mcar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a data frame of any length containing any given number of NA values according to the missing completely at random mechanism. — gen.mcar","text":"","code":"syn_na <- gen.mcar(50,c(.25,.75,.044),c(1.1,.56,1.56),3,.47)"},{"path":"https://describe.jpmonteagudo.com/reference/geom.mad.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the median of distances to the geometric mean for a 2D+ space — geom.mad","title":"Calculate the median of distances to the geometric mean for a 2D+ space — geom.mad","text":"calculating median absolute deviation matrices arrays","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.mad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the median of distances to the geometric mean for a 2D+ space — geom.mad","text":"","code":"geom.mad(x, iters = 1000, na.rm = FALSE, ...)"},{"path":"https://describe.jpmonteagudo.com/reference/geom.mad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the median of distances to the geometric mean for a 2D+ space — geom.mad","text":"x numeric vector matrix containing set points n-dimensions iters number iterations used Weiszfeld algorithm na.rm set FALSE default ignore NA. Set TRUE remove NA ... optional arguments specify alternative tolerance convergence current tolerance set 1e-8.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.mad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the median of distances to the geometric mean for a 2D+ space — geom.mad","text":"numeric vector length 1L.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.mad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the median of distances to the geometric mean for a 2D+ space — geom.mad","text":"","code":"d <- rlnorm(60,1,1.4) geom.mad(d,iters = 100) #> [1] 2.579694  x <- matrix(rlnorm(60,1,1.4), ncol = 4) sapply(x,function(z) geom.mad(z,iters = 100)) #>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 #> [39] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0"},{"path":"https://describe.jpmonteagudo.com/reference/geom.mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the geometric mean for a set of non-negative, non-zero observations. — geom.mean","title":"Calculate the geometric mean for a set of non-negative, non-zero observations. — geom.mean","text":"geometric mean nth root product 'n' observations. multiplies observations set can thought exponential arithmetic mean logarithms. use  definition create function. #' 'geom.mean' function calculate mean numeric columns  matrix data frame.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the geometric mean for a set of non-negative, non-zero observations. — geom.mean","text":"","code":"geom.mean(x, ..., na.rm = FALSE)"},{"path":"https://describe.jpmonteagudo.com/reference/geom.mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the geometric mean for a set of non-negative, non-zero observations. — geom.mean","text":"x numeric vector, matrix data frame ... additional parameters passed 'mean()' na.rm indicate whether remove NAs","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the geometric mean for a set of non-negative, non-zero observations. — geom.mean","text":"numeric vector length equal greater 1L.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.mean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the geometric mean for a set of non-negative, non-zero observations. — geom.mean","text":"using logarithms, observations must non-negative. Additionally, using geometric mean SD variance, measuring log-normal dispersion log-normal distribution","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the geometric mean for a set of non-negative, non-zero observations. — geom.mean","text":"","code":"x <- rlnorm(60,1,1.4) geom.mean(x) #> [1] 2.935312  d <- matrix(rlnorm(60,1,1.3),ncol = 4) sapply(d,geom.mean) #>  [1]  1.1901508  5.6155205  4.2355163  0.5866222  0.2827114  0.2038519 #>  [7]  5.5658876  2.5982427 30.1366854  5.7303559  8.2038590 15.4051006 #> [13]  1.4177416  5.2757841  8.4100822 16.1215550  7.3261233  4.6996654 #> [19]  0.8792454  7.0176505  5.2087798  6.1998514  4.7149512  2.0909333 #> [25]  2.4597859  6.6430643  3.3977755  0.9239095  1.8641276  0.4892589 #> [31]  0.7732588  2.2524209  0.2624821  0.3026721 11.3968244  1.2845332 #> [37]  0.2448280  2.3473283 15.1407540  6.4297174  4.8249393 12.6653471 #> [43]  0.9970525  7.0188259  1.2671733  2.7209836 48.3663786  9.5856263 #> [49]  7.3773170  0.6435045  0.9781359 52.9501775  0.6561991  3.5924096 #> [55]  8.6741070 10.2203963 11.1992366  2.1988452  0.9349309  1.8231497"},{"path":"https://describe.jpmonteagudo.com/reference/geom.median.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the geometric median for non-collinear points in 2D+ Euclidean Space — geom.median","title":"Calculate the geometric median for non-collinear points in 2D+ Euclidean Space — geom.median","text":"Using Weiszfeld algorithm iterative method compute geometric median set points Euclidean space. general, measures central tendency minimize sum Euclidean distance center point set. try come estimate center first using best guess approximating calculating  distance point newly chosen point set updating center distance smaller calculated using best, initial guess.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the geometric median for non-collinear points in 2D+ Euclidean Space — geom.median","text":"","code":"geom.median(x, iters = 1000, tol = 1e-08, na.rm = FALSE)"},{"path":"https://describe.jpmonteagudo.com/reference/geom.median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the geometric median for non-collinear points in 2D+ Euclidean Space — geom.median","text":"x vector non-collinear points iters number iterations used Weiszfeld algorithm tol tolerance value used check convergence changes successive guesses.Default set 1e-8. na.rm set FALSE. handle NAs, set TRUE.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the geometric median for non-collinear points in 2D+ Euclidean Space — geom.median","text":"numeric vector length 1L.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.median.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the geometric median for non-collinear points in 2D+ Euclidean Space — geom.median","text":"sample 1D set points use median grouped.median instead. geom.median function used samples points +2D space.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.median.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the geometric median for non-collinear points in 2D+ Euclidean Space — geom.median","text":"","code":"d <- rlnorm(60,1,1.4) geom.median(d,iters = 100) #> [1] 3.42183  x <- matrix(rlnorm(60,1,1.4),ncol = 4) sapply(x,function(z) geom.median(z,iters = 500, tol = 1e-10)) #>  [1]   2.8689125   5.7581058   1.3059394   0.5424226   9.7830680   3.7935418 #>  [7]   1.9450839   2.9949558  17.3965460   1.0228233   0.9520175   1.1417235 #> [13]   0.2955292   8.5632466   3.5584231   3.6329346   2.5582251   1.3307935 #> [19]   0.8583133   8.9584656   0.3691108   5.0350251   0.8961421   4.0359201 #> [25]   0.9637082   1.3064606  32.3661228   6.9281697   0.1349493   3.2445523 #> [31]   1.4440648   0.5536200   3.6462537   3.2607320   1.7161627  43.0251571 #> [37]   0.1166980   8.7890545   1.8136972   6.8149503   1.4396546   1.1836343 #> [43]   0.2479492   2.0274365  87.3780513  10.8653963  28.3833021   9.7859868 #> [49]  13.4902579   9.6217579   5.2885780   1.2025685   1.2890318   0.2890441 #> [55]   2.6962319   9.5744486  11.5269939   3.1055343   1.2627872 272.2509961"},{"path":"https://describe.jpmonteagudo.com/reference/geom.sd.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the geometric standard deviation (GSD) — geom.sd","title":"Calculate the geometric standard deviation (GSD) — geom.sd","text":"GSD  standard deviation geometric mean set non-negative,non-zero observations.GSD dimensionless (unitless) multiplicative factor. describes range mean divided GSD mean multiplied GSD. multiplicative nature, GSD added/subtracted mean.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.sd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the geometric standard deviation (GSD) — geom.sd","text":"","code":"geom.sd(x, ..., na.rm = FALSE)"},{"path":"https://describe.jpmonteagudo.com/reference/geom.sd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the geometric standard deviation (GSD) — geom.sd","text":"x numeric vector, matrix data frame ... additional parameters passed 'geom.mean()' na.rm indicate whether remove NAs","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.sd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the geometric standard deviation (GSD) — geom.sd","text":"numeric vector length equal greater 1L.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.sd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the geometric standard deviation (GSD) — geom.sd","text":"order calculate GSD, use imputation methods deal missingness preserve structure matrix data frame. Note cases, method might lead artificial increase decrease association  outcome original independent variables.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.sd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the geometric standard deviation (GSD) — geom.sd","text":"","code":"d <- rlnorm(60,1,1.3) geom.sd(d) #> [1] 3.880721  x <- matrix(rlnorm(60,1,1.4), ncol = 4) sapply(x,geom.sd) #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #> [39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1"},{"path":"https://describe.jpmonteagudo.com/reference/geom.var.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the geometric variance of a set of observations of non-negative, non-zero observations. — geom.var","title":"Calculate the geometric variance of a set of observations of non-negative, non-zero observations. — geom.var","text":"Calculate geometric variance set observations non-negative, non-zero observations.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the geometric variance of a set of observations of non-negative, non-zero observations. — geom.var","text":"","code":"geom.var(x, ..., na.rm = FALSE)"},{"path":"https://describe.jpmonteagudo.com/reference/geom.var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the geometric variance of a set of observations of non-negative, non-zero observations. — geom.var","text":"x numeric vector, matrix data frame ... additional parameters passed 'geom.mean()' na.rm indicate whether remove NAs","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.var.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the geometric variance of a set of observations of non-negative, non-zero observations. — geom.var","text":"numeric vector length equal greater 1L.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the geometric variance of a set of observations of non-negative, non-zero observations. — geom.var","text":"","code":"d <- rlnorm(60,1,1.3) geom.var(d) #> [1] 4.315597  x <- matrix(rlnorm(60,1,1.4), ncol = 4) sapply(x,geom.var) #>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #> [39] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1"},{"path":"https://describe.jpmonteagudo.com/reference/geom.zscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the number of GSD by which the raw value is above/below the mean. — geom.zscore","title":"Calculate the number of GSD by which the raw value is above/below the mean. — geom.zscore","text":"formula makes use change base property logarithms.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.zscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the number of GSD by which the raw value is above/below the mean. — geom.zscore","text":"","code":"geom.zscore(x, ..., na.rm = FALSE)"},{"path":"https://describe.jpmonteagudo.com/reference/geom.zscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the number of GSD by which the raw value is above/below the mean. — geom.zscore","text":"x numeric vector, matrix data frame ... additional parameters passed 'geom.mean()' na.rm indicate whether remove NAs","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.zscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the number of GSD by which the raw value is above/below the mean. — geom.zscore","text":"matrix array z-scores length > 1L.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/geom.zscore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the number of GSD by which the raw value is above/below the mean. — geom.zscore","text":"","code":"d <- rlnorm(60,1,1.4) geom.zscore(d) #>  [1] -1.383639914 -0.308561264 -0.241446981  0.819578374 -1.172421586 #>  [6] -0.626914902  1.203299597  1.087485196  0.912627420  1.358433139 #> [11]  0.054506910 -0.648600941  0.368679125  0.819145597  2.031297503 #> [16] -1.885971305  0.116419973  0.457776428 -0.176872570 -1.521711082 #> [21]  0.535347046 -0.825025073  0.324535473  0.683902145  1.020648024 #> [26] -1.521748253  0.839738983 -0.805249687 -1.281230341  1.047812454 #> [31]  0.897459245 -0.345050443  0.551486120 -0.897705333 -0.263144972 #> [36] -0.211874841 -0.379186892  0.528724808  1.247322512 -0.535776000 #> [41] -0.157244066  1.336276041 -0.422399544 -2.457693906  0.331801967 #> [46] -0.921093158 -1.021355410  1.143087782  2.062041445 -1.058253914 #> [51]  0.794366008 -0.212254708 -0.001160515  0.965430790  0.063134371 #> [56] -0.889689044 -0.548871519  0.485814933 -2.217850089  0.851818841  x <- matrix(rlnorm(60,1,1.4), ncol = 4) sapply(x,geom.zscore) #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #> Warning: NaNs produced #>  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN #> [20] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN #> [39] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN #> [58] NaN NaN NaN"},{"path":"https://describe.jpmonteagudo.com/reference/grouped.mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate mean for grouped data using frequency, either percent or counts. — grouped.mean","title":"Calculate mean for grouped data using frequency, either percent or counts. — grouped.mean","text":"function split character element x find midpoint lower upper bounds.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/grouped.mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate mean for grouped data using frequency, either percent or counts. — grouped.mean","text":"","code":"grouped.mean(x, freq, freq_format = \"count\", na.rm = FALSE)"},{"path":"https://describe.jpmonteagudo.com/reference/grouped.mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate mean for grouped data using frequency, either percent or counts. — grouped.mean","text":"x character vector categories ranges freq numeric vector containing category counts percentages freq_format intended freq format. Use percent want freq converted percent na.rm remove NA calculations","code":""},{"path":"https://describe.jpmonteagudo.com/reference/grouped.mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate mean for grouped data using frequency, either percent or counts. — grouped.mean","text":"numeric vector length 1L","code":""},{"path":"https://describe.jpmonteagudo.com/reference/grouped.mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate mean for grouped data using frequency, either percent or counts. — grouped.mean","text":"","code":"age <- c(\"0-4\",\"5-9\",\"10-14\",          \"15-19\",\"20-24\",          \"25-29\",\"30-34\",          \"35-39\",\"40-44\",          \"45-49\",\"50-54\",          \"55-59\",\"60-64\",          \"65-69\",\"70-74\",          \"75-79\",\"80-84\",          \"85-89\")  freq <- seq(5400, 300, by = -300) grouped.mean(age,freq, freq_format = \"percent\") #> [1] 30.33333"},{"path":"https://describe.jpmonteagudo.com/reference/grouped.median.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate median of grouped data using frequency, either percent or counts. — grouped.median","title":"Calculate median of grouped data using frequency, either percent or counts. — grouped.median","text":"Calculate median grouped data using frequency, either percent counts.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/grouped.median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate median of grouped data using frequency, either percent or counts. — grouped.median","text":"","code":"grouped.median(x, freq, freq_format = \"count\", na.rm = FALSE)"},{"path":"https://describe.jpmonteagudo.com/reference/grouped.median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate median of grouped data using frequency, either percent or counts. — grouped.median","text":"x character vector categories ranges freq numeric vector containing category counts percentages freq_format intended freq format. Use percent want freq converted percent na.rm remove NA calculations","code":""},{"path":"https://describe.jpmonteagudo.com/reference/grouped.median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate median of grouped data using frequency, either percent or counts. — grouped.median","text":"numeric vector length 1L","code":""},{"path":"https://describe.jpmonteagudo.com/reference/grouped.median.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate median of grouped data using frequency, either percent or counts. — grouped.median","text":"","code":"age <- c(\"0-4\",\"5-9\",\"10-14\",          \"15-19\",\"20-24\",          \"25-29\",\"30-34\",          \"35-39\",\"40-44\",          \"45-49\",\"50-54\",          \"55-59\",\"60-64\",          \"65-69\",\"70-74\",          \"75-79\",\"80-84\",          \"85-89\")  freq <- seq(5400, 300, by = -300) grouped.median(age,freq) #> [1] 26.69231"},{"path":"https://describe.jpmonteagudo.com/reference/harm.mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the harmonic mean for matrices, data frames and vectors. — harm.mean","title":"Calculate the harmonic mean for matrices, data frames and vectors. — harm.mean","text":"harmonic mean reciprocal arithmetic mean reciprocals set observations. robust measure central tendency arithmetic mean presence outliers since tends smallest elements set observations.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/harm.mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the harmonic mean for matrices, data frames and vectors. — harm.mean","text":"","code":"harm.mean(x, na.rm = FALSE, ...)"},{"path":"https://describe.jpmonteagudo.com/reference/harm.mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the harmonic mean for matrices, data frames and vectors. — harm.mean","text":"x object containing set observations matrix, data frame vector. na.rm logical default set FALSE. remove NAs set argument TRUE ... additional arguments passed methods","code":""},{"path":"https://describe.jpmonteagudo.com/reference/harm.mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the harmonic mean for matrices, data frames and vectors. — harm.mean","text":"numeric vector length equal greater 1L","code":""},{"path":"https://describe.jpmonteagudo.com/reference/harm.mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the harmonic mean for matrices, data frames and vectors. — harm.mean","text":"","code":"d <- rlnorm(60,1,1.4) harm.mean(d) #> [1] 1.495732  x <- matrix(rlnorm(60,1,1.4),ncol = 4) sapply(x,harm.mean) #>  [1]  0.2685039  1.7605401  6.0788895  1.3066609  2.4995595  2.6394999 #>  [7]  0.9869711  0.6755205  2.0548151  1.6722350  8.7384523 23.1463036 #> [13]  2.6732866  4.7499818  2.4630947  6.3085369  3.6909861  3.7857109 #> [19] 12.9110196  0.6822292 20.6354324  4.4315853  3.5013577  1.2406822 #> [25]  2.1610006  4.5866904  0.1511927  1.1710131  6.1742552  1.7998899 #> [31]  0.8862656  1.1163089  3.7812273  0.2756109  9.2047618  0.1304835 #> [37]  1.3435625  0.9029795  0.4732932  0.6010541  3.8578433  2.2986370 #> [43]  1.7839077  0.1054974  0.4256878  2.2618206  0.7951304  0.8909415 #> [49] 11.8148474  3.4757966  0.6304115  1.4103326  1.8241883  1.0487372 #> [55]  0.7049171  2.5281158  7.6727309  3.7344211  2.0540104  4.6783634"},{"path":"https://describe.jpmonteagudo.com/reference/hotdeck.impute.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute values in X by randomly selecting data points from recorded observations in Y. — hotdeck.impute","title":"Impute values in X by randomly selecting data points from recorded observations in Y. — hotdeck.impute","text":"Hot deck imputation (HDI) univariate imputation technique , respondent recipient missing value, find donor similar values across subset categorical numerical predictors use fill recipient's missing observation. reason, HDI used stratification across categorical variables. current implementation HDI allows user choose one four selection methods: deterministic, random sampling possible donors, k-nearest neighbors random sampling using weights probabilities. function iteratively impute missing values across variables missing observations using selection method specified function arguments.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/hotdeck.impute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute values in X by randomly selecting data points from recorded observations in Y. — hotdeck.impute","text":"","code":"hotdeck.impute(   data,   method = \"deterministic\",   k = NULL,   seed = NULL,   na.rm = TRUE )"},{"path":"https://describe.jpmonteagudo.com/reference/hotdeck.impute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute values in X by randomly selecting data points from recorded observations in Y. — hotdeck.impute","text":"data matrix data frame containing missing values least one predictor method selection method imputing missing values based donor similarity. Can one : \"deterministic\" Select donor value multiple repetitions CDI. \"rand_from_all\" Select different donor value repetition CDI. \"rand_nearest_k\" Select one random donor value subset k nearest neighbors repetition CDI. \"weighted_rand\" Select one random donor probability-weighted choice repetition CDI. k number nearest neighbors select using rand_nearest_k method. seed numeric seed reproducible results every method except deterministic selection na.rm indicates removal NA values every row matrix data frame","code":""},{"path":"https://describe.jpmonteagudo.com/reference/hotdeck.impute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute values in X by randomly selecting data points from recorded observations in Y. — hotdeck.impute","text":"matrix data frame imputed values","code":""},{"path":"https://describe.jpmonteagudo.com/reference/hotdeck.impute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute values in X by randomly selecting data points from recorded observations in Y. — hotdeck.impute","text":"","code":"data <- gen.mcar(100,rho = c(.56,.23,.18),sigma = c(1,2,.5),n_vars = 3,na_prob = .18) hotdeck.impute(data) #>               V1          V2           V3 #> 1    0.793918367  0.34842553  0.096484456 #> 2   -0.140513958  1.30490257  0.210867432 #> 3    0.455805199  2.63357399 -0.284916489 #> 4   -1.145572907 -2.47433574  0.401348744 #> 5   -0.249650688  0.82157465  1.060543391 #> 6   -0.420298275 -1.40719171  0.651553088 #> 7    0.195664504 -1.37517092 -0.227900727 #> 8    0.357319514  1.43309765  0.301787300 #> 9   -0.123617979  0.03801310  0.015393905 #> 10  -0.766214223 -0.21304442  0.497724369 #> 11  -0.929714217 -2.00316563 -0.311322416 #> 12   0.455805199  3.28619502 -0.284916489 #> 13   1.356836852  2.62202967 -0.363966359 #> 14  -0.787135595 -1.50197115 -0.037141272 #> 15  -0.384798672  0.73347007  0.301787300 #> 16   0.330680560 -1.64207015  0.424407564 #> 17  -0.554620450 -0.84942483 -0.841088182 #> 18   0.121572315  2.46150428 -0.284916489 #> 19  -0.047596117 -0.36621160 -0.648726990 #> 20  -0.776251591  0.63926730 -1.038441499 #> 21   0.831441251  0.56349273  0.333960472 #> 22   0.846307837  0.56349273  0.428459498 #> 23   0.391720548 -0.31146293  0.253671466 #> 24   1.267996586  1.78922592 -0.447186498 #> 25  -0.506361788  1.82979125  0.747770152 #> 26  -0.464481897 -1.50347827 -0.251499344 #> 27   0.261218000  0.74985730  0.902492269 #> 28   0.630080977 -0.89300060  0.310415003 #> 29  -0.339626156 -2.06463426  0.507565624 #> 30  -0.423344808  0.54364121  0.087841477 #> 31  -0.618271528  0.95571200 -0.060193883 #> 32   1.482201891  3.21814603 -0.284916489 #> 33  -2.508166352 -1.82545193 -0.541317066 #> 34  -0.167578034  1.66061756 -0.007680438 #> 35   0.038212877 -0.66046752  0.128258867 #> 36  -1.059609603  0.07184500  0.497724369 #> 37   0.385425895  0.77902962 -0.648320996 #> 38  -1.967087684 -3.94148293 -0.169528772 #> 39   0.954968861 -0.30749269  1.060543391 #> 40  -1.663360585 -1.78002689 -0.258879342 #> 41  -2.202734880 -1.82545193 -0.953870127 #> 42  -0.763563826 -1.38767763 -0.037141272 #> 43   0.162080394 -1.46964122  0.669444315 #> 44  -0.651567165 -4.19433225 -0.180146756 #> 45  -1.605718058  0.07820747 -0.410978336 #> 46   0.333204975 -0.11607128  1.032321689 #> 47  -1.058900921 -0.27601757 -0.632560961 #> 48  -0.085849546 -2.65767137 -0.567192658 #> 49   0.497932993 -1.51907416  0.310415003 #> 50   1.633989657  1.64559315 -0.447186498 #> 51   0.479451881 -1.80402503  0.072651573 #> 52   1.714762992 -1.36519066 -0.406395918 #> 53   0.453160034  1.80594524  0.641476290 #> 54  -0.003241127  1.48909711  0.301787300 #> 55  -2.256534856  0.09721225  0.069183803 #> 56  -1.224658552 -1.82241245 -0.258879342 #> 57  -0.318962624 -1.50347827 -0.277072134 #> 58   0.112831695  1.32205763  0.301787300 #> 59   0.391720548 -0.41039171  0.158517037 #> 60   0.543648621 -0.83179666  0.424102832 #> 61  -1.063811352 -2.47433574  0.625606034 #> 62  -0.274129717 -2.06687812 -0.311322416 #> 63   0.217006032  0.96611246 -0.454732254 #> 64  -0.359385718  0.54364121  0.025292829 #> 65   0.112831695  0.75018483  1.492182341 #> 66  -0.670748026 -2.14789355 -0.311322416 #> 67  -0.846555519  0.19240668  0.544215939 #> 68  -0.081054893  0.78887164 -0.110969235 #> 69  -0.047049347  1.66061756 -0.243268640 #> 70  -1.948787086 -2.24791408 -0.006655192 #> 71  -0.673668581  0.95571200 -0.148162846 #> 72  -1.489644085 -3.14894390  0.598354026 #> 73  -1.605718058  0.09721225 -0.002727320 #> 74  -0.493883101 -1.23780127  0.167089512 #> 75  -0.160798368 -1.36183585  0.651553088 #> 76   0.283600226 -0.02328607  1.032321689 #> 77   1.091262650  0.37279281  0.514197397 #> 78   0.444400297  0.15437507 -0.648320996 #> 79   0.391720548 -0.35860837  0.295168952 #> 80  -0.526310288 -1.05611479 -0.841088182 #> 81  -0.307840173 -4.55672324 -1.497238031 #> 82   1.085168884  0.37279281  0.735879158 #> 83   0.001207184  1.66061756 -0.225530901 #> 84  -1.680244716 -2.16233503 -0.006655192 #> 85  -0.846555519  0.19240668  0.497724369 #> 86   0.455805199  1.93376881 -0.117663038 #> 87  -0.359385718  0.38580138 -0.115826706 #> 88   0.333444133  1.46051420  0.228706569 #> 89   0.014222696 -2.16233503 -0.567192658 #> 90  -0.496357607 -0.54902799 -0.432970332 #> 91  -0.350786392  2.30811671  0.364921554 #> 92   0.391720548 -0.35742990  0.295168952 #> 93   0.209578829  1.30490257 -0.101981868 #> 94   1.234670140  1.62043185 -0.447186498 #> 95  -0.199819784  0.69916286  0.301787300 #> 96  -0.923208042 -1.48474289  0.578647932 #> 97   0.165903102 -0.88841087  0.669444315 #> 98  -0.846555519  0.19240668  0.507099929 #> 99   0.455805199  2.90014909  0.034230785 #> 100 -1.058900921 -0.82641784 -0.317079321"},{"path":"https://describe.jpmonteagudo.com/reference/mar.transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform non-missing data to missing values with user-specified probability of MAR — mar.transform","title":"Transform non-missing data to missing values with user-specified probability of MAR — mar.transform","text":"Transform complete case dataset according MAR mechanism.MAR mechanism assumes probability missingness variable depends observed data missing data . function introduces missing values selected features dataset, missing values determined values causative (target) feature.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mar.transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform non-missing data to missing values with user-specified probability of MAR — mar.transform","text":"","code":"mar.transform(input, target, features, na_rate)"},{"path":"https://describe.jpmonteagudo.com/reference/mar.transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform non-missing data to missing values with user-specified probability of MAR — mar.transform","text":"input data transform using MAR mechanism target variable used causative feature features variables NA values introduced using causative feature na_rate proportion missing values added data","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mar.transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform non-missing data to missing values with user-specified probability of MAR — mar.transform","text":"matrix data frame containing NAs","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mar.transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform non-missing data to missing values with user-specified probability of MAR — mar.transform","text":"","code":"set.seed(123) data <- gen.mcar(100,rho = c(.15,.25,.12,.45,.34,.54),sigma = c(1,2,1,2),n_vars = 4, na_prob = 0)  mar.transform(data,\"V1\",c(\"V2\",\"V3\"), na_rate = .25) #> Warning: One or more features are at risk of being entirely NA. #>               V1          V2           V3          V4 #> 1   -0.560475647          NA           NA -0.10870782 #> 2   -0.230177489  0.43890141  1.229901703 -0.07693965 #> 3    1.558708314 -0.02018912  0.113321644 -0.34213763 #> 4    0.070508391 -0.66606849  0.512615342 -1.22758235 #> 5    0.129287735 -1.84291758 -0.446775346 -1.40156838 #> 6    1.715064987  0.42548293 -0.034399523  1.60862474 #> 7    0.460916206 -1.41377325 -0.710987188 -3.65506210 #> 8   -1.265061235          NA           NA -2.24347826 #> 9   -0.686852852          NA           NA  2.38387824 #> 10  -0.445661970          NA           NA  3.07054916 #> 11   1.224081797 -0.77045043  0.373040290  2.80692212 #> 12   0.359813827  1.31011577  0.375755980  1.98141531 #> 13   0.400771451 -3.07892452  1.154089964 -2.04864243 #> 14   0.110682716 -0.07666186 -0.474783259 -1.25249611 #> 15  -0.555841135          NA           NA -1.56643493 #> 16   1.786913137  1.13156617  2.088307907  4.21896599 #> 17   0.497850478  0.35831629 -0.292284557 -0.01978737 #> 18  -1.966617157          NA           NA -4.58910274 #> 19   0.701355902 -1.46977481 -1.088126658  1.61466054 #> 20  -0.472791408          NA           NA -0.72096614 #> 21  -1.067823706          NA           NA -1.02676922 #> 22  -0.217974915 -1.93890224  0.462581120  1.59948550 #> 23  -1.026004448          NA           NA -2.24098233 #> 24  -0.728891229          NA           NA  0.77256775 #> 25  -0.625039268          NA           NA -0.62367973 #> 26  -1.686693311          NA           NA -0.81710759 #> 27   0.837787044  0.71678293 -0.450596021  0.20298897 #> 28   0.153373118  0.20016954 -0.647011187  0.51466709 #> 29  -1.138136937          NA           NA  1.16051478 #> 30   1.253814921  0.23514186 -0.672181289  0.24816516 #> 31   0.426464221  2.98435368  2.113316899  4.32329398 #> 32  -0.295071483          NA           NA -1.84825272 #> 33   0.895125661  0.35007052  0.434175544 -0.05785329 #> 34   0.878133488 -0.57199336 -0.528137441  2.18259134 #> 35   0.821581082 -3.81355923 -0.520016385 -0.31655188 #> 36   0.688640254  2.44366660 -1.003887589 -2.89312439 #> 37   0.553917654 -2.72205347 -0.159860150 -2.47531237 #> 38  -0.061911711  1.44457797  0.450434971  0.40690741 #> 39  -0.305962664          NA           NA  2.32810853 #> 40  -0.380471001          NA           NA -1.94431513 #> 41  -0.694706979          NA           NA  0.02242443 #> 42  -0.207917278 -0.58083716 -0.558300879  0.66403287 #> 43  -1.265396352          NA           NA  1.71806274 #> 44   2.168955965 -2.34437461 -0.681243614  0.24607600 #> 45   1.207961998 -2.80444418 -0.004369181 -0.02262170 #> 46  -1.123108583          NA           NA -2.29831263 #> 47  -0.402884835          NA           NA -1.10630322 #> 48  -0.466655354          NA           NA -2.02608923 #> 49   0.779965118  4.38668614 -0.271032563 -0.13691625 #> 50  -0.083369066 -2.56994874  0.340058465 -0.64315612 #> 51   0.253318514  1.63364829 -0.233261092  1.84672281 #> 52  -0.028546755  1.51211856 -0.484975044 -3.01713255 #> 53  -0.042870457  0.64402694 -0.314754798 -0.77516374 #> 54   1.368602284 -1.58335498  0.345304508  0.92410660 #> 55  -0.225770986 -0.30393353  1.475580738 -0.24809495 #> 56   1.516470604 -0.09950470  0.270286559  1.62930176 #> 57  -1.548752804          NA           NA  0.43073881 #> 58   0.584613750 -0.56106584  0.723528484  0.80102662 #> 59   0.123854244  1.96899609  0.002864226 -3.08848203 #> 60   0.215941569 -0.67590323 -1.455975120  2.50143679 #> 61   0.379639483  2.19549401 -0.319940016  0.18161627 #> 62  -0.502323453          NA           NA -0.47917608 #> 63  -0.333207384          NA           NA -0.55051359 #> 64  -1.018575383          NA           NA  3.47416178 #> 65  -1.071791226          NA           NA  1.93673545 #> 66   0.303528641  0.68076548  1.593631500  1.42550096 #> 67   0.448209779  1.39319798  0.036727207  1.20133780 #> 68   0.053004227 -0.94071299 -1.721540313 -3.08886788 #> 69   0.922267468  1.29870877 -0.101338021  2.05494510 #> 70   2.050084686  1.34460553  0.629362247  1.44212557 #> 71  -0.491031166          NA           NA  3.71863157 #> 72  -2.309168876          NA           NA -3.67433945 #> 73   1.005738524  0.23435792  0.908706564  0.77477643 #> 74  -0.709200763          NA           NA  0.58428732 #> 75  -0.688008616          NA           NA  0.43838219 #> 76   1.025571370 -1.85952091 -0.265830082 -0.92656278 #> 77  -0.284773007          NA           NA -1.56153920 #> 78  -1.220717712          NA           NA -0.65152227 #> 79   0.181303480  0.91756035  0.494779460  0.74174666 #> 80  -0.138891362 -0.94802618 -0.049168155 -3.00198988 #> 81   0.005764186 -2.10086206 -1.695806248 -1.92834526 #> 82   0.385280401  2.61337111  0.912181480  1.94178380 #> 83  -0.370660032          NA           NA  0.05555461 #> 84   0.644376549 -1.51812793 -0.167386907 -1.67866638 #> 85  -0.220486562 -0.53335857  0.039129561  0.47385172 #> 86   0.331781964 -0.29035550  0.195791837  2.33906496 #> 87   1.096839013  2.52377700  0.580031032  2.45839981 #> 88   0.435181491  0.29811160  1.698697789  0.13672509 #> 89  -0.325931586          NA           NA -0.70501919 #> 90   1.148807618 -0.64264377  0.407662119  1.41099113 #> 91   0.993503856  0.72208931  1.393344067  1.03626986 #> 92   0.548396960 -0.47750574  1.126914994 -1.98909747 #> 93   0.238731735  0.25864634  1.172345986  2.53389439 #> 94  -0.627906076          NA           NA -2.76846310 #> 95   1.360652449 -2.18374651  2.162466427  1.33402169 #> 96  -0.600259587          NA           NA  2.83854922 #> 97   2.187332993  1.84402470  2.397805347  2.72163176 #> 98   1.532610626 -2.01444576 -1.024398036  0.80617075 #> 99  -0.235700359          NA           NA -2.39399903 #> 100 -1.026420900          NA           NA -1.05282380"},{"path":"https://describe.jpmonteagudo.com/reference/mcar.transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform non-missing data to missing values with user-specified probability of MCAR — mcar.transform","title":"Transform non-missing data to missing values with user-specified probability of MCAR — mcar.transform","text":"Transform complete case dataset according MCAR mechanism.MCAR mechanism assumes probability missingness cases, therefore,missing data related observed data. transform.mcar uses binomial distribution generate NA  index possible NA values replace percentage data points input.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mcar.transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform non-missing data to missing values with user-specified probability of MCAR — mcar.transform","text":"","code":"mcar.transform(input, na_prob)"},{"path":"https://describe.jpmonteagudo.com/reference/mcar.transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform non-missing data to missing values with user-specified probability of MCAR — mcar.transform","text":"input data transform using MCAR mechanism na_prob desired probability NA count defined probability success Bernoulli trial.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mcar.transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform non-missing data to missing values with user-specified probability of MCAR — mcar.transform","text":"data frame matrix containing NAs","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mcar.transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform non-missing data to missing values with user-specified probability of MCAR — mcar.transform","text":"","code":"set.seed(123) data <- data.frame(x1 = stats::rnorm(100),x2 = stats::rnorm(100),y = stats::rnorm(100)) mcar.transform(data,na_prob = .25) #> Warning: One or more columns are at risk of being entirely NA. #>               x1          x2           y #> 1   -0.560475647          NA  2.19881035 #> 2   -0.230177489  0.25688371  1.31241298 #> 3    1.558708314 -0.24669188 -0.26514506 #> 4    0.070508391          NA  0.54319406 #> 5    0.129287735 -0.95161857 -0.41433995 #> 6             NA -0.04502772          NA #> 7    0.460916206 -0.78490447 -0.78860284 #> 8             NA -1.66794194 -0.59461727 #> 9   -0.686852852 -0.38022652  1.65090747 #> 10  -0.445661970  0.91899661 -0.05402813 #> 11   1.224081797 -0.57534696  0.11924524 #> 12   0.359813827  0.60796432  0.24368743 #> 13   0.400771451 -1.61788271  1.23247588 #> 14            NA -0.05556197          NA #> 15  -0.555841135  0.51940720          NA #> 16            NA  0.30115336  1.67569693 #> 17            NA  0.10567619 -0.44116322 #> 18            NA -0.64070601 -0.72306597 #> 19            NA          NA -1.23627312 #> 20  -0.472791408 -1.02412879 -1.28471572 #> 21            NA  0.11764660 -0.57397348 #> 22            NA -0.94747461  0.61798582 #> 23            NA -0.49055744  1.10984814 #> 24  -0.728891229          NA          NA #> 25  -0.625039268  1.84386201 -0.36365730 #> 26  -1.686693311          NA  0.05974994 #> 27   0.837787044          NA -0.70459646 #> 28            NA  0.07796085 -0.71721816 #> 29  -1.138136937          NA  0.88465050 #> 30   1.253814921 -0.07130809 -1.01559258 #> 31            NA  1.44455086  1.95529397 #> 32            NA          NA          NA #> 33   0.895125661  0.04123292  0.21453883 #> 34   0.878133488          NA -0.73852770 #> 35   0.821581082 -2.05324722 -0.57438869 #> 36   0.688640254  1.13133721 -1.31701613 #> 37            NA          NA -0.18292539 #> 38            NA          NA  0.41898240 #> 39            NA  1.90910357  0.32430434 #> 40  -0.380471001 -1.44389316 -0.78153649 #> 41  -0.694706979          NA          NA #> 42            NA -0.26219749 -0.50219872 #> 43            NA -1.57214416  1.49606067 #> 44   2.168955965 -1.51466765 -1.13730362 #> 45   1.207961998 -1.60153617 -0.17905159 #> 46  -1.123108583 -0.53090652  1.90236182 #> 47  -0.402884835          NA          NA #> 48  -0.466655354  0.68791677 -1.35984070 #> 49   0.779965118  2.10010894 -0.66476944 #> 50  -0.083369066          NA  0.48545998 #> 51            NA  0.78773885 -0.37560287 #> 52            NA  0.76904224 -0.56187636 #> 53  -0.042870457  0.33220258          NA #> 54   1.368602284 -1.00837661  0.09049665 #> 55  -0.225770986 -0.11945261  1.59850877 #> 56            NA -0.28039534 -0.08856511 #> 57            NA  0.56298953          NA #> 58   0.584613750          NA  0.63075412 #> 59   0.123854244  0.97697339 -0.11363990 #> 60   0.215941569 -0.37458086          NA #> 61            NA  1.05271147 -0.52111732 #> 62            NA -1.04917701 -0.48987045 #> 63  -0.333207384 -1.26015524  0.04715443 #> 64  -1.018575383  3.24103993  1.30019868 #> 65  -1.071791226 -0.41685759  2.29307897 #> 66   0.303528641  0.29822759  1.54758106 #> 67            NA  0.63656967 -0.13315096 #> 68   0.053004227 -0.48378063 -1.75652740 #> 69   0.922267468  0.51686204 -0.38877986 #> 70   2.050084686  0.36896453  0.08920722 #> 71  -0.491031166          NA  0.84501300 #> 72  -2.309168876          NA  0.96252797 #> 73   1.005738524 -0.03406725          NA #> 74  -0.709200763          NA -1.39527435 #> 75  -0.688008616 -0.74133610          NA #> 76   1.025571370 -1.09599627 -0.44655722 #> 77            NA  0.03778840  0.17480270 #> 78  -1.220717712  0.31048075  0.07455118 #> 79   0.181303480  0.43652348          NA #> 80  -0.138891362          NA  0.02467498 #> 81   0.005764186 -1.06332613 -1.66747510 #> 82   0.385280401          NA          NA #> 83            NA -0.34965039  0.38602657 #> 84            NA -0.86551286 -0.26565163 #> 85            NA          NA  0.11814451 #> 86   0.331781964 -0.19717589          NA #> 87   1.096839013  1.10992029  0.22101947 #> 88   0.435181491  0.08473729  1.64084617 #> 89  -0.325931586  0.75405379 -0.21905038 #> 90   1.148807618          NA  0.16806538 #> 91   0.993503856          NA  1.16838387 #> 92   0.548396960 -0.32468591          NA #> 93   0.238731735  0.09458353  1.14526311 #> 94  -0.627906076 -0.89536336 -0.57746800 #> 95   1.360652449          NA          NA #> 96  -0.600259587  1.99721338          NA #> 97   2.187332993  0.60070882  1.86685184 #> 98   1.532610626 -1.25127136 -1.35090269 #> 99  -0.235700359 -0.61116592  0.02098359 #> 100 -1.026420900 -1.18548008          NA"},{"path":"https://describe.jpmonteagudo.com/reference/mnar.transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform non-missing data to missing values with user-specified probability of MNAR. — mnar.transform","title":"Transform non-missing data to missing values with user-specified probability of MNAR. — mnar.transform","text":"MNAR mechanism assumes probability cause missingness unknown us lie unobserved data. mechanism generate missing values looking variable's lowest values replace NA.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mnar.transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform non-missing data to missing values with user-specified probability of MNAR. — mnar.transform","text":"","code":"mnar.transform(input, target, features, na_rate)"},{"path":"https://describe.jpmonteagudo.com/reference/mnar.transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform non-missing data to missing values with user-specified probability of MNAR. — mnar.transform","text":"input data transform using MAR mechanism target variable used causative feature features variables NA values introduced using causative feature na_rate proportion missing values added data","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mnar.transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform non-missing data to missing values with user-specified probability of MNAR. — mnar.transform","text":"matrix data frame containing NAs","code":""},{"path":"https://describe.jpmonteagudo.com/reference/mnar.transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform non-missing data to missing values with user-specified probability of MNAR. — mnar.transform","text":"","code":"set.seed(123) data <- gen.mcar(100,rho = c(.15,.25,.12,.45,.34,.54),sigma = c(1,2,1,2),n_vars = 4, na_prob = 0)  mnar.transform(data,\"V1\",c(\"V2\",\"V3\"), na_rate = .25) #>               V1          V2         V3          V4 #> 1   -0.560475647          NA 1.92166997 -0.10870782 #> 2   -0.230177489  0.43890141 1.22990170 -0.07693965 #> 3    1.558708314 -0.02018912 0.11332164 -0.34213763 #> 4    0.070508391          NA 0.51261534 -1.22758235 #> 5    0.129287735          NA         NA -1.40156838 #> 6    1.715064987  0.42548293         NA  1.60862474 #> 7    0.460916206          NA         NA -3.65506210 #> 8   -1.265061235          NA         NA -2.24347826 #> 9   -0.686852852          NA 1.38909629  2.38387824 #> 10  -0.445661970  1.68349957         NA  3.07054916 #> 11   1.224081797          NA 0.37304029  2.80692212 #> 12   0.359813827  1.31011577 0.37575598  1.98141531 #> 13   0.400771451          NA 1.15408996 -2.04864243 #> 14   0.110682716 -0.07666186         NA -1.25249611 #> 15  -0.555841135  0.86030892         NA -1.56643493 #> 16   1.786913137  1.13156617 2.08830791  4.21896599 #> 17   0.497850478  0.35831629         NA -0.01978737 #> 18  -1.966617157          NA         NA -4.58910274 #> 19   0.701355902          NA         NA  1.61466054 #> 20  -0.472791408          NA         NA -0.72096614 #> 21  -1.067823706 -0.08771603         NA -1.02676922 #> 22  -0.217974915          NA 0.46258112  1.59948550 #> 23  -1.026004448          NA 0.77317256 -2.24098233 #> 24  -0.728891229          NA 0.47897832  0.77256775 #> 25  -0.625039268  3.45848931         NA -0.62367973 #> 26  -1.686693311          NA         NA -0.81710759 #> 27   0.837787044  0.71678293         NA  0.20298897 #> 28   0.153373118  0.20016954         NA  0.51466709 #> 29  -1.138136937          NA 0.48857687  1.16051478 #> 30   1.253814921  0.23514186         NA  0.24816516 #> 31   0.426464221  2.98435368 2.11331690  4.32329398 #> 32  -0.295071483  0.80427002         NA -1.84825272 #> 33   0.895125661  0.35007052 0.43417554 -0.05785329 #> 34   0.878133488          NA         NA  2.18259134 #> 35   0.821581082          NA         NA -0.31655188 #> 36   0.688640254  2.44366660         NA -2.89312439 #> 37   0.553917654          NA         NA -2.47531237 #> 38  -0.061911711  1.44457797 0.45043497  0.40690741 #> 39  -0.305962664  3.68321913 0.39565082  2.32810853 #> 40  -0.380471001          NA         NA -1.94431513 #> 41  -0.694706979  1.17927660         NA  0.02242443 #> 42  -0.207917278          NA         NA  0.66403287 #> 43  -1.265396352          NA 0.99562998  1.71806274 #> 44   2.168955965          NA         NA  0.24607600 #> 45   1.207961998          NA         NA -0.02262170 #> 46  -1.123108583          NA 1.51002281 -2.29831263 #> 47  -0.402884835          NA         NA -1.10630322 #> 48  -0.466655354  1.22027075         NA -2.02608923 #> 49   0.779965118  4.38668614         NA -0.13691625 #> 50  -0.083369066          NA 0.34005846 -0.64315612 #> 51   0.253318514  1.63364829         NA  1.84672281 #> 52  -0.028546755  1.51211856         NA -3.01713255 #> 53  -0.042870457  0.64402694         NA -0.77516374 #> 54   1.368602284          NA 0.34530451  0.92410660 #> 55  -0.225770986 -0.30393353 1.47558074 -0.24809495 #> 56   1.516470604 -0.09950470 0.27028656  1.62930176 #> 57  -1.548752804  0.64861389 0.70237616  0.43073881 #> 58   0.584613750          NA 0.72352848  0.80102662 #> 59   0.123854244  1.96899609         NA -3.08848203 #> 60   0.215941569          NA         NA  2.50143679 #> 61   0.379639483  2.19549401         NA  0.18161627 #> 62  -0.502323453          NA         NA -0.47917608 #> 63  -0.333207384          NA         NA -0.55051359 #> 64  -1.018575383  6.10316898 1.27002998  3.47416178 #> 65  -1.071791226          NA 1.90927162  1.93673545 #> 66   0.303528641  0.68076548 1.59363150  1.42550096 #> 67   0.448209779  1.39319798 0.03672721  1.20133780 #> 68   0.053004227          NA         NA -3.08886788 #> 69   0.922267468  1.29870877         NA  2.05494510 #> 70   2.050084686  1.34460553 0.62936225  1.44212557 #> 71  -0.491031166          NA 0.67440628  3.71863157 #> 72  -2.309168876          NA 0.35665245 -3.67433945 #> 73   1.005738524  0.23435792 0.90870656  0.77477643 #> 74  -0.709200763  3.99598095         NA  0.58428732 #> 75  -0.688008616          NA 0.58574037  0.43838219 #> 76   1.025571370          NA         NA -0.92656278 #> 77  -0.284773007 -0.01071018 0.10058226 -1.56153920 #> 78  -1.220717712  0.24772062         NA -0.65152227 #> 79   0.181303480  0.91756035 0.49477946  0.74174666 #> 80  -0.138891362          NA         NA -3.00198988 #> 81   0.005764186          NA         NA -1.92834526 #> 82   0.385280401  2.61337111 0.91218148  1.94178380 #> 83  -0.370660032          NA 0.25053676  0.05555461 #> 84   0.644376549          NA         NA -1.67866638 #> 85  -0.220486562          NA 0.03912956  0.47385172 #> 86   0.331781964 -0.29035550 0.19579184  2.33906496 #> 87   1.096839013  2.52377700 0.58003103  2.45839981 #> 88   0.435181491  0.29811160 1.69869779  0.13672509 #> 89  -0.325931586  1.39326536         NA -0.70501919 #> 90   1.148807618          NA 0.40766212  1.41099113 #> 91   0.993503856  0.72208931 1.39334407  1.03626986 #> 92   0.548396960          NA 1.12691499 -1.98909747 #> 93   0.238731735  0.25864634 1.17234599  2.53389439 #> 94  -0.627906076          NA         NA -2.76846310 #> 95   1.360652449          NA 2.16246643  1.33402169 #> 96  -0.600259587  3.76915594 0.08093331  2.83854922 #> 97   2.187332993  1.84402470 2.39780535  2.72163176 #> 98   1.532610626          NA         NA  0.80617075 #> 99  -0.235700359          NA         NA -2.39399903 #> 100 -1.026420900          NA 0.85019544 -1.05282380"},{"path":"https://describe.jpmonteagudo.com/reference/pmean.match.html","id":null,"dir":"Reference","previous_headings":"","what":"Imputation of missing values through predictive mean matching — pmean.match","title":"Imputation of missing values through predictive mean matching — pmean.match","text":"Predictive mean matching (PMM) imputation technique introduced  Donald . Rubin 1987. imputation method aims maintain natural variability data avoid implausible imputations can occur univariate imputation methods.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/pmean.match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Imputation of missing values through predictive mean matching — pmean.match","text":"","code":"pmean.match(   data,   family = \"AUTO\",   robust = FALSE,   k = 3,   char_to_factor = FALSE,   seed = NULL,   verbose = FALSE )"},{"path":"https://describe.jpmonteagudo.com/reference/pmean.match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Imputation of missing values through predictive mean matching — pmean.match","text":"data numeric matrix data frame least 2 columns. family distribution family observations. family arguments defaults 'AUTO'; automatically select distribution family (gaussian, binomial, multinomial) based type variable (numeric factor). distribution family dictates regression model used (lm,glm, multinom). However, user can change family argument match response variable distribution function adapt input using generalized linear model beta regression. robust logical indicated whether use robust estimation methods ignore . set 'TRUE', function make use robust linear generalized linear models make prediction. k numeric vector indicating number nearest neighbors extract imputation. Currently k defaults 3 can changed. char_to_factor transform character variable unordered factor variable seed numeric vector used reproducible results. Used sample predicted value time. verbose verbose error handling","code":""},{"path":"https://describe.jpmonteagudo.com/reference/pmean.match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Imputation of missing values through predictive mean matching — pmean.match","text":"matrix data frame containing imputed dataset.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/pmean.match.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Imputation of missing values through predictive mean matching — pmean.match","text":"predictive mean matching different conditional mean imputation(CMI)? PMM combination CMI HDI. Predictive mean matching (PMM) uses regression observed variables estimate missing values, like CMI, however, PMM also fill missing value randomly sampling observed values whose predicted values closest predicted values missing observation. currently done using nearest neighbor approach set number neighbors (3) can changed depending data.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/pmean.match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imputation of missing values through predictive mean matching — pmean.match","text":"","code":"set.seed(123) data <- data.frame(x1 = stats::rnorm(100),x2 = stats::rnorm(100),y = stats::rnorm(100)) data$x1[sample(1:100, 20)] <- NA data$x2[sample(1:100, 15)] <- NA data$y[sample(1:100, 10)] <- NA fact_dat <- data.frame(data, c = gl(5,20)) pmean.match(fact_dat, robust = TRUE) #>               x1          x2           y c #> 1   -0.560475647 -0.71040656  2.19881035 1 #> 2   -0.230177489  0.76904224  1.31241298 1 #> 3    1.558708314 -0.24669188 -0.26514506 1 #> 4    0.070508391 -0.34754260  0.54319406 1 #> 5    0.129287735 -0.95161857 -0.41433995 1 #> 6    1.715064987 -0.34754260 -0.70459646 1 #> 7    0.460916206 -0.78490447 -0.78860284 1 #> 8   -1.265061235 -1.66794194 -0.59461727 1 #> 9    0.460916206 -0.38022652  1.65090747 1 #> 10  -0.445661970  0.91899661 -0.05402813 1 #> 11   0.701355902 -0.57534696  0.11924524 1 #> 12   0.359813827  0.60796432  0.24368743 1 #> 13   0.400771451 -1.61788271  1.23247588 1 #> 14   0.110682716 -0.05556197 -0.51606383 1 #> 15  -0.555841135  0.51940720 -0.99250715 1 #> 16   1.786913137  0.30115336  1.67569693 1 #> 17   0.497850478  0.10567619 -0.44116322 1 #> 18  -0.325931586 -0.64070601 -0.72306597 1 #> 19   0.701355902 -0.84970435 -1.23627312 1 #> 20  -0.472791408 -1.02412879 -1.28471572 1 #> 21  -1.067823706 -0.96185663 -0.57397348 2 #> 22  -0.217974915 -0.94747461  0.61798582 2 #> 23  -1.026004448 -0.49055744  1.10984814 2 #> 24  -0.728891229 -0.25609219  0.70758835 2 #> 25  -0.625039268  1.84386201 -0.36365730 2 #> 26  -1.686693311 -0.65194990  0.05974994 2 #> 27   0.837787044  0.23538657 -0.70459646 2 #> 28   0.153373118  0.07796085 -0.70459646 2 #> 29  -1.138136937 -0.96185663  0.88465050 2 #> 30   0.837787044 -0.07130809 -1.01559258 2 #> 31   0.426464221  1.44455086  1.95529397 2 #> 32  -0.295071483  0.45150405  0.54319406 2 #> 33   0.895125661  0.04123292  0.21453883 2 #> 34  -0.555841135 -0.42249683 -0.73852770 2 #> 35   0.821581082 -2.05324722 -0.57438869 2 #> 36   0.688640254  1.13133721 -1.31701613 2 #> 37   0.553917654 -0.23627957 -0.18292539 2 #> 38   0.426464221  0.73994751  0.41898240 2 #> 39  -0.305962664  1.90910357  0.32430434 2 #> 40  -0.380471001 -0.94747461 -0.78153649 2 #> 41  -0.694706979  0.70178434 -0.78862197 3 #> 42  -0.207917278 -0.26219749 -0.50219872 3 #> 43  -0.083369066 -1.57214416  1.49606067 3 #> 44   2.168955965 -1.51466765 -1.13730362 3 #> 45   1.207961998 -1.60153617 -0.17905159 3 #> 46   1.532610626 -0.53090652  1.90236182 3 #> 47  -0.402884835 -1.46175558  1.49606067 3 #> 48  -0.466655354  0.68791677 -1.35984070 3 #> 49   0.779965118  2.10010894 -0.36365730 3 #> 50  -0.083369066 -1.28703048  0.48545998 3 #> 51   0.253318514  0.78773885 -0.37560287 3 #> 52  -0.028546755  0.76904224 -0.56187636 3 #> 53  -0.042870457  0.33220258 -0.34391723 3 #> 54   1.368602284 -1.00837661  0.09049665 3 #> 55   1.558708314 -0.53090652  1.59850877 3 #> 56   1.516470604 -0.28039534 -0.08856511 3 #> 57  -0.560475647  0.70178434  1.08079950 3 #> 58   0.584613750 -0.37243876  0.63075412 3 #> 59   0.123854244  0.91899661 -0.11363990 3 #> 60   0.400771451 -0.37458086 -1.53290200 3 #> 61   0.497850478  1.05271147 -0.52111732 4 #> 62   1.025571370 -1.04917701 -0.48987045 4 #> 63   1.532610626 -1.26015524  0.04715443 4 #> 64  -1.018575383  3.24103993  1.30019868 4 #> 65  -1.071791226 -0.41685759 -0.36365730 4 #> 66   0.303528641  0.29822759  1.54758106 4 #> 67   0.448209779  0.63656967 -0.13315096 4 #> 68   0.053004227 -0.48378063 -1.75652740 4 #> 69   0.922267468  0.51686204  0.42816676 4 #> 70   0.460916206  0.36896453  0.08920722 4 #> 71  -0.491031166  1.84386201  0.84501300 4 #> 72  -2.309168876 -0.96185663  0.96252797 4 #> 73   1.005738524 -0.03406725  0.68430943 4 #> 74   1.558708314  0.21444531 -1.39527435 4 #> 75  -0.688008616 -0.24669188  0.68430943 4 #> 76   1.025571370 -1.09599627 -0.44655722 4 #> 77  -0.284773007  0.03778840  0.17480270 4 #> 78  -0.466655354  0.31048075  0.07455118 4 #> 79   0.181303480  0.43652348  0.42816676 4 #> 80   0.331781964 -0.45836533  0.02467498 4 #> 81   0.005764186  1.26318518 -1.66747510 5 #> 82   0.385280401  1.26318518  0.73649596 5 #> 83  -0.370660032 -0.34965039  0.38602657 5 #> 84  -0.560475647 -0.86551286  0.16806538 5 #> 85  -0.220486562 -0.23627957  0.11814451 5 #> 86   0.331781964 -0.19717589  0.13403865 5 #> 87   1.096839013 -0.49929202  0.22101947 5 #> 88   0.435181491  0.08473729  1.64084617 5 #> 89  -0.325931586  0.75405379 -0.21905038 5 #> 90   1.148807618 -0.49929202  0.16806538 5 #> 91   0.993503856  0.21444531  1.16838387 5 #> 92   0.548396960 -0.32468591  0.38602657 5 #> 93   0.435181491  0.09458353  1.14526311 5 #> 94  -0.627906076 -0.89536336 -0.57746800 5 #> 95   1.360652449 -1.31080153  2.00248273 5 #> 96  -0.600259587  1.99721338  0.06670087 5 #> 97   2.187332993  0.60070882  1.86685184 5 #> 98   1.532610626 -1.25127136 -1.35090269 5 #> 99  -0.235700359  0.75405379  0.02098359 5 #> 100 -1.026420900 -1.18548008  1.24991457 5"},{"path":"https://describe.jpmonteagudo.com/reference/stoc.impute.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic regression imputation with custom regression variance — stoc.impute","title":"Stochastic regression imputation with custom regression variance — stoc.impute","text":"method corrects lack variability conditional mean imputation (CMI) adding error term conditional mean calculation. method effective CMI reducing bias imputed values. Work well MCAR MAR data.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/stoc.impute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stochastic regression imputation with custom regression variance — stoc.impute","text":"","code":"stoc.impute(   data,   family = \"AUTO\",   tol = NULL,   robust = FALSE,   char_to_factor = FALSE,   verbose = FALSE )"},{"path":"https://describe.jpmonteagudo.com/reference/stoc.impute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stochastic regression imputation with custom regression variance — stoc.impute","text":"data numeric matrix data frame least 2 columns. family distribution family observations. family arguments defaults 'AUTO'; automatically select distribution family (gaussian, binomial, multinomial) based type variable (numeric factor). distribution family dictates regression model used (lm,glm, multinom). However, user can change family argument match response variable distribution function adapt input using generalized linear model beta regression. tol tolerance,numeric vector length 1 used multiplicative factor standard deviation generalized linear models. sample size increases, tolerance value decreased represent decreasing variability sample estimate. robust logical indicated whether use robust estimation methods ignore . set 'TRUE', function make use robust linear generalized linear models make prediction. char_to_factor transform character variable unordered factor variable verbose verbose error handling","code":""},{"path":"https://describe.jpmonteagudo.com/reference/stoc.impute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stochastic regression imputation with custom regression variance — stoc.impute","text":"matrix data frame containing imputed dataset.","code":""},{"path":"https://describe.jpmonteagudo.com/reference/stoc.impute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stochastic regression imputation with custom regression variance — stoc.impute","text":"","code":"data <- data.frame(x1 = c(stats::rnorm(87),rep(NA,13)), x2 = stats::rnorm(100),y = stats::rnorm(100)) stoc.impute(data,tol = 1e-3) #>              x1          x2           y #> 1    0.41142992 -0.19988983 -1.19736350 #> 2   -0.03303616 -0.64511396  0.86636613 #> 3   -2.46589819  0.16532102  0.86415249 #> 4    2.57145815  0.43881870 -1.19862236 #> 5   -0.20529926  0.88330282  0.63949200 #> 6    0.65119328 -2.05233698  2.43022665 #> 7    0.27376649 -1.63637927 -0.55721548 #> 8    1.02467323  1.43040234  0.84490424 #> 9    0.81765945  1.04662885 -0.78220185 #> 10  -0.20979317  0.43528895  1.11071142 #> 11   0.37816777  0.71517841  0.24982472 #> 12  -0.94540883  0.91717492  1.65191539 #> 13   0.85692301 -2.66092280 -1.45897073 #> 14  -0.46103834  1.11027710 -0.05129789 #> 15   2.41677335 -0.48498760 -0.52692518 #> 16  -1.65104890  0.23061683 -0.19726487 #> 17  -0.46398724 -0.29515780 -0.62957874 #> 18   0.82537986  0.87196495 -0.83384358 #> 19   0.51013255 -0.34847245  0.57872237 #> 20  -0.58948104  0.51850377 -1.08758071 #> 21  -0.99678074 -0.39068498  1.48403093 #> 22   0.14447570 -1.09278721 -1.18620659 #> 23  -0.01430741  1.21001051  0.10107915 #> 24  -1.79028124  0.74090001  0.53298929 #> 25   0.03455107  1.72426224  0.58673534 #> 26   0.19023032  0.06515393 -0.30174666 #> 27   0.17472640  1.12500275  0.07950200 #> 28  -1.05501704  1.97541905  0.96126415 #> 29   0.47613328 -0.28148212 -1.45646592 #> 30   1.37857014 -1.32295111 -0.78173971 #> 31   0.45623640 -0.23935157  0.32040231 #> 32  -1.13558847 -0.21404124 -0.44478198 #> 33  -0.43564547  0.15168050  1.37000399 #> 34   0.34610362  1.71230498  0.67325386 #> 35  -0.64704563 -0.32614389  0.07216675 #> 36  -2.15764634  0.37300466 -1.50775732 #> 37   0.88425082 -0.22768406  0.02610023 #> 38  -0.82947761  0.02045071 -0.31641587 #> 39  -0.57356027  0.31405766 -0.10234651 #> 40   1.50390061  1.32821470 -1.18155923 #> 41  -0.77414493  0.12131838  0.49865804 #> 42   0.84573154  0.71284232 -1.03895644 #> 43  -1.26068288  0.77886003 -0.22622198 #> 44  -0.35454240  0.91477327  0.38142583 #> 45  -0.07355602 -0.57439455 -0.78351579 #> 46  -1.16865142  1.62688121  0.58299141 #> 47  -0.63474826 -0.38095674 -1.31651040 #> 48  -0.02884155 -0.10578417 -2.80977468 #> 49   0.67069597  1.40405027  0.46496799 #> 50  -1.65054654  1.29408391  0.84053983 #> 51  -0.34975424 -1.08999187 -0.28584542 #> 52   0.75640644 -0.87307100  0.50412625 #> 53  -0.53880916 -1.35807906 -1.15591653 #> 54   0.22729192  0.18184719 -0.12714861 #> 55   0.49222857  0.16484087 -1.94151838 #> 56   0.26783502  0.36411469  1.18118089 #> 57   0.65325768  0.55215771  1.85991086 #> 58  -0.12270866 -0.60189285  1.07401226 #> 59  -0.41367651 -0.99369859 -0.02734697 #> 60  -2.64314895  1.02678506 -0.03333034 #> 61  -0.09294102  0.75106130 -1.51606762 #> 62   0.43028470 -1.50916654  0.79038534 #> 63   0.53539884 -0.09514745 -0.21073418 #> 64  -0.55527835 -0.89594782 -0.65674293 #> 65   1.77950291 -2.07075107 -1.41202579 #> 66   0.28642442  0.15012013 -0.29976250 #> 67   0.12631586 -0.07921171 -0.84906114 #> 68   1.27226678 -0.09736927 -0.39703052 #> 69  -0.71846622  0.21615254 -1.21759999 #> 70  -0.45033862  0.88246516  1.68758948 #> 71   2.39745248  0.20559750 -0.01600253 #> 72   0.01112919 -0.61643584  1.07494508 #> 73   1.63356842 -0.73479925 -2.60169967 #> 74  -1.43850664 -0.13180279 -0.45319783 #> 75  -0.19051680  0.31001699 -0.67548229 #> 76   0.37842390 -1.03968035 -1.22292618 #> 77   0.30003855 -0.18430887  1.54660915 #> 78  -1.00563626  0.96726726 -1.41528192 #> 79   0.01925927 -0.10828009  0.31839026 #> 80  -1.07742065 -0.69842067  0.84643629 #> 81   0.71270333 -0.27594517  0.17819019 #> 82   1.08477509  1.11464855 -0.87525548 #> 83  -2.22498770  0.55004396  0.94116581 #> 84   1.23569346  1.23667580  0.17058808 #> 85  -1.24104450  0.13909786 -1.06349791 #> 86   0.45476927  0.41027510 -1.38804905 #> 87   0.65990264 -0.55845691  2.08671743 #> 88   0.60166893  0.60537067 -0.67850315 #> 89  -0.03018459 -0.50633354 -1.85557165 #> 90   1.08759846 -1.42056550  0.53325936 #> 91  -0.93886617  0.12799297  0.31023026 #> 92  -0.53194294  1.94585122 -1.35383434 #> 93   0.87463907  0.80091434 -1.94295641 #> 94   0.76643879  1.16525339 -0.11630252 #> 95  -2.23792177  0.35885572  1.13939629 #> 96   0.10692378 -0.60855718  0.63612404 #> 97   0.71217004 -0.20224086 -0.49293742 #> 98  -1.30663050 -0.27324811 -0.83418823 #> 99   0.51496908 -0.46869978  0.27106676 #> 100 -1.02692927  0.70416728  0.15735335"},{"path":"https://describe.jpmonteagudo.com/reference/w.harm.mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the weighted harmonic mean for matrices, data frames and vectors — w.harm.mean","title":"Calculate the weighted harmonic mean for matrices, data frames and vectors — w.harm.mean","text":"Calculate weighted harmonic mean matrices, data frames vectors","code":""},{"path":"https://describe.jpmonteagudo.com/reference/w.harm.mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the weighted harmonic mean for matrices, data frames and vectors — w.harm.mean","text":"","code":"w.harm.mean(x, w = NULL, na.rm = FALSE, ...)"},{"path":"https://describe.jpmonteagudo.com/reference/w.harm.mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the weighted harmonic mean for matrices, data frames and vectors — w.harm.mean","text":"x object containing set observations whose weighted harmonic mean computed w numerical vector weights length x na.rm logical default set FALSE. remove NAs set argument TRUE ... additional arguments passed methods","code":""},{"path":"https://describe.jpmonteagudo.com/reference/w.harm.mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the weighted harmonic mean for matrices, data frames and vectors — w.harm.mean","text":"numeric vector length equal greater 1L","code":""},{"path":"https://describe.jpmonteagudo.com/reference/w.harm.mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the weighted harmonic mean for matrices, data frames and vectors — w.harm.mean","text":"","code":"x <- matrix(rlnorm(60,1,1.4),ncol = 4) w <- matrix(rnorm(60,0,0.23), ncol = 4) w.harm.mean(x,w) #> [1] 94.57722"}]
